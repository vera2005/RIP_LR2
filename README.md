Вариант 11 — Перевод слов
Идея:
A → слово на русском.
B → переводит слово с русского на английский.
Задача:
- Реализовать WebClient запрос.
- Обработать Mono/Flux.
- Покрыть логирование через фильтры.
(Неоптимальная) логика: хранит большой словарь в файле, на каждый
запрос читает весь файл, использует сложные regex-мэппинги (с lookaround),
делает heavy normalization (NFKC) через Unicode normalize каждый вызов.
Что нужно сделать: реализовать file-read + regex-based mapping.
Пример:
- Список слов создаётся заново.
- Поиск через Regex.

Запуск проекта:
Шаг 1: Откройте два терминала в корневой папке проекта
Шаг 2: В первом терминале запустите сервер:
# Запустите сервер на порту 8081
.\mvnw.cmd clean compile -pl server
.\mvnw.cmd spring-boot:run -pl server
Шаг 3: Во втором терминале запустите клиент:
# Запустите клиент на порту 8082
.\mvnw.cmd clean compile -pl client
.\mvnw.cmd spring-boot:run -pl client

Реализованный проект сознательно содержит несколько уровней неоптимальной логики, которая будет предметом профилирования и оптимизации в следующей лабораторной работе. Основные неоптимальности сосредоточены в сервисе перевода (TranslationService) и включают следующие аспекты:

Чтение файла словаря при каждом запросе. Вместо того чтобы загрузить словарь в память при старте приложения и использовать кэшированную версию, система каждый раз читает файл dictionary.txt с диска. Это приводит к избыточным операциям ввода-вывода, особенно заметным при высокой нагрузке, когда одно и то же содержимое файла считывается многократно без необходимости.

Использование тяжёлой Unicode нормализации NFKC. Для каждого входящего слова и для каждой строки словаря выполняется полная нормализация Unicode в форму NFKC, которая является наиболее ресурсоёмкой. Эта операция выполняется неоднократно: при нормализации входного слова, при обработке каждой строки словаря, а затем ещё раз в процессе постобработки результата. Такое дублирование дорогостоящих операций существенно замедляет обработку.

Применение сложных регулярных выражений с lookaround. Поиск перевода осуществляется с использованием регулярных выражений, содержащих конструкции lookahead и lookbehind. Эти конструкции требуют значительных вычислительных ресурсов для сопоставления, особенно при работе с большими объёмами данных. Кроме того, поиск осуществляется полным перебором всех записей словаря вместо использования эффективных структур данных.

Неэффективные алгоритмы поиска и обработки. Вместо прямого доступа к записям словаря по ключу используется линейный поиск с проверкой каждой записи через регулярные выражения. При пакетной обработке выполняются множественные сортировки одних и тех же данных, преобразования регистра туда и обратно, удаление дубликатов через промежуточные коллекции — все эти операции увеличивают время выполнения и потребление памяти без реальной необходимости.

Создание избыточных промежуточных объектов. В процессе обработки создаются дополнительные списки, наборы и временные коллекции, которые увеличивают нагрузку на сборщик мусора. Например, при постобработке результата строка разбивается на массив символов, который преобразуется в список для последующей сборки обратно в строку без изменения порядка.

Блокирующие операции в реактивном контексте. Несмотря на использование реактивной модели, внутри выполняются блокирующие операции (чтение файла, сложные вычисления), что может привести к исчерпанию пула потоков при высокой нагрузке.

Эти неоптимальности создают значительный простор для оптимизации, включая внедрение кэширования, оптимизацию алгоритмов поиска, устранение дублирующих операций и переход к более эффективным структурам данных, что и будет продемонстрировано в следующей лабораторной работе по профилированию.

Примеры работы программы представлены в прикрепленном pdf файле
